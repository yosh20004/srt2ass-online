1
00:00:01,210 --> 00:00:08,090
在本视频中，我们将讨论内核执行与内存传输重叠的第二个要求

2
00:00:08,450 --> 00:00:12,470
即异步内存传输。在这里，

3
00:00:12,590 --> 00:00:18,280
我们有一个程序，我在前面的视频中展示了常见的CUDA程序执行步骤。

4
00:00:18,290 --> 00:00:20,870
在这个实现中，

5
00:00:20,900 --> 00:00:23,600
内存复制是同步操作。

6
00:00:23,690 --> 00:00:29,740
它们会阻塞主机执行。为了让内存传输与内核执行重叠，

7
00:00:29,840 --> 00:00:34,290
我们需要异步执行内存传输。为此

8
00:00:34,370 --> 00:00:44,030
我们将使用cudaMemCpyAsync函数。CudaMemCpyAsync函数与cudaMemCpy函数几乎相似。

9
00:00:44,080 --> 00:00:51,150
但是我们可以将此内存操作将在其中执行的流作为参数提供给

10
00:00:51,150 --> 00:00:58,920
此函数。要异步执行内存操作，CUDA运行时需要保证

11
00:00:58,920 --> 00:01:04,950
操作系统不会在内存传输操作过程中移动属于被复制内存的虚拟内存。

12
00:01:04,950 --> 00:01:07,280
内存传输操作。

13
00:01:07,410 --> 00:01:10,970
因此，我们必须在此函数调用中使用固定内存。

14
00:01:11,160 --> 00:01:18,360
如果我们使用未固定的内存，那么此内存传输将是一个阻塞主机执行的同步操作。

15
00:01:18,750 --> 00:01:22,050
好的，让我们使用此函数调用来执行

16
00:01:22,080 --> 00:01:29,640
异步内存传输操作。在此示例中，我们将执行内存传输

17
00:01:29,640 --> 00:01:32,670
在主机和设备之间异步进行。

18
00:01:32,950 --> 00:01:39,970
在这里，我们的内核类似于我们在先前的常见CUDA程序步骤演示示例中使用的内核，

19
00:01:39,990 --> 00:01:46,340
它只是对传输到设备的数据进行计算。

20
00:01:46,980 --> 00:01:50,000
所以让我们专注于主要功能。在这里，

21
00:01:50,010 --> 00:01:56,620
我们首先要添加主机指针以保存GPU计算的输入和输出内存。

22
00:01:56,700 --> 00:02:00,930
然后我们必须为这些指针分配固定的主机内存。

23
00:02:01,200 --> 00:02:05,550
因此，要分配固定内存，我们可以使用cudaMallocHost函数

24
00:02:10,420 --> 00:02:13,240
现在我们需要创建新的CUDA流。

25
00:02:13,580 --> 00:02:19,880
因此，在这里，我们声明了cuda流类型变量，然后我们可以使用cudaStreamCreate函数

26
00:02:20,060 --> 00:02:28,670
来创建一个新流。然后我们可以使用cudaMemCpyAsync函数执行异步内存传输

27
00:02:28,680 --> 00:02:30,520
使用此新流。

28
00:02:31,010 --> 00:02:37,680
请记住，我们必须将流作为cudaMemCpyAsync函数的最后一个参数提供。

29
00:02:38,090 --> 00:02:40,070
现在我们可以启动内核了。

30
00:02:40,220 --> 00:02:44,990
但请记住，这里也要提供新闻流作为第四个内核启动参数。

31
00:02:45,100 --> 00:02:51,120
但是在这里，我们不会使用任何共享内存，因此将第三个内核启动参数设置为0

32
00:02:51,170 --> 00:02:52,630
第四个参数设置为新流。

33
00:02:52,640
。

34
00:02:54,840 --> 00:02:58,940
好了，现在我们还必须使我们的内存传输设备到主机异步。

35
00:02:58,940 --> 00:03:02,650
所以我们可以使用cudaMemCpyAsync函数

36
00:03:02,680 --> 00:03:05,860
而不是cudaMemCpy函数

37
00:03:05,920 --> 00:03:10,260
这里也是。

38
00:03:10,470 --> 00:03:17,310
最后，我们可以在此流上调用cudaStreamSynchronize，以等待该流中的所有函数执行完毕。

39
00:03:17,370 --> 00:03:19,210
流执行。

40
00:03:19,230 --> 00:03:22,790
现在让我们看看这个程序的执行情况。

41
00:03:22,830 --> 00:03:25,400
在nvvp中。

42
00:03:25,860 --> 00:03:30,110
所以让我先编译这个程序并用nvvp命令运行它。

43
00:03:39,400 --> 00:03:40,760
好的，这是我们的输出。

44
00:03:48,660 --> 00:03:56,240
现在让我打开常见CUDA程序执行步骤的输出时间线程序。

45
00:03:56,300 --> 00:04:01,810
现在，如您所见，这两种结果非常相似。在新流中，

46
00:04:01,810 --> 00:04:08,000
所有操作按顺序执行。记住，在这个程序中，

47
00:04:08,150 --> 00:04:11,940
所有这些CUDA操作相对于主机都是异步的。

48
00:04:12,290 --> 00:04:17,820
但如果我们使用一个流，放入该流的操作将按顺序执行。

49
00:04:18,050 --> 00:04:21,800
所以这里即使所有操作都是异步的，

50
00:04:21,910 --> 00:04:28,000
但是在设备上，所有这些CUDA操作都会按顺序执行。

51
00:04:28,320 --> 00:04:30,370
现在我要做的是，

52
00:04:30,470 --> 00:04:36,240
我将使用另一个流执行我们在流一中执行的相同操作集。

53
00:04:36,270 --> 00:04:43,760
通常，当我们使用多个流时，我们将相同的主机内存分区，并使用不同的流将内存块传输到设备。

54
00:04:43,790 --> 00:04:46,400
但是这里为了简化示例，我将为新的内核启动分配单独的内存指针。

56
00:04:54,890 --> 00:05:15,110
然后我必须使用cudaMallocHost函数为该内核启动分配内存。

57
00:05:15,360 --> 00:05:17,860
现在我们这里需要另一个流。

58
00:05:18,280 --> 00:05:24,730
所以让我添加另一个流变量，并使用cudaStreamCreate函数创建该流。

59
00:05:25,080 --> 00:05:29,790
然后我们也可以使用新流执行相同的操作集。

60
00:05:29,800 --> 00:05:36,970
因此，让我首先异步将内存从设备传输到主机，然后我们可以在此新流中启动内核。

61
00:05:36,970 --> 00:05:37,970
然后我们可以异步将该内核启动的结果复制回主机。

63
00:05:55,970 --> 00:06:02,930
现在让我再次用nvvp运行这个程序。

64
00:06:03,240 --> 00:06:03,760
好的，

65
00:06:03,920 --> 00:06:08,220
正如你从这个输出中看到的那样，这个程序执行中发生了多个重叠。

66
00:06:08,240 --> 00:06:17,720
这里，两个内核执行是重叠的。两个流的内核执行和主机到设备的内存传输也是重叠的。

67
00:06:17,750 --> 00:06:24,530
但同一方向上的内存传输没有重叠。

68
00:06:24,530 --> 00:06:29,980
这是由于只有一条PCI-e总线。

69
00:06:30,290 --> 00:06:37,610
因此，连接只允许一个方向上的一次内存传输。如果

70
00:06:37,610 --> 00:06:41,270
传输方向不同，则允许两个内存传输。

71
00:06:41,290 --> 00:06:47,780
记住，如果我们在这里使用同步内存复制，那么所有这些操作将一个接一个地执行

72
00:06:47,840 --> 00:06:51,650
这将导致执行时间延长。

73
00:06:52,060 --> 00:06:58,160
但在这里，通过异步内存传输，我们可以将内存传输与内核执行

74
00:06:58,340 --> 00:07:05,390
和不同方向的内存传输重叠。因此，通过这种方式，通过重叠这些操作，我们可以减少

75
00:07:05,390 --> 00:07:07,780
CUDA程序的执行时间。
